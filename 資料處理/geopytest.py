
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.extra.rate_limiter import RateLimiter

if __name__ == '__main__':

    # ç¯„ä¾‹è³‡æ–™
    df = pd.DataFrame({
        'åœ°å€': [
            'å°ä¸­å¸‚æ²™é¹¿å€ä¸­æ¸…è·¯å…«æ®µ 496è™Ÿ',
            'å°ä¸­å¸‚æ²™é¹¿å€ç¦æˆè·¯130å·· 21è™Ÿ',
            'å°ä¸­å¸‚éœ§å³°å€æ–°ç”Ÿè·¯ 7è™Ÿ'
        ]
    })

    # åˆå§‹åŒ–åœ°ç†ç·¨ç¢¼å™¨
    geolocator = (user_agent="my_geocoder")

    # åŠ ä¸Šé€Ÿç‡é™åˆ¶å™¨ï¼ˆé¿å…è¢«å°é–ï¼‰
    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1)

    # æ–°å¢æ¬„ä½ï¼šç¶“ç·¯åº¦
    df['location'] = df['åœ°å€'].apply(geocode)
    df['latitude'] = df['location'].apply(lambda loc: loc.latitude if loc else None)
    df['longitude'] = df['location'].apply(lambda loc: loc.longitude if loc else None)

    # ç§»é™¤ä¸­é–“æ¬„ä½
    df.drop(columns=['location'], inplace=True)

    print(df)
    

#     import os
# import re
# import pandas as pd
# from geopy.geocoders import Nominatim
# from geopy.extra.rate_limiter import RateLimiter

# # =======================
# # ğŸ“Œ åŸºæœ¬è¨­å®š
# # =======================

# ADDRESS_REPLACE_MAP = {
#     "å°åŒ—ç¸£": "æ–°åŒ—å¸‚", "è‡ºåŒ—ç¸£": "æ–°åŒ—å¸‚",
#     "å°ä¸­ç¸£": "å°ä¸­å¸‚", "è‡ºä¸­ç¸£": "å°ä¸­å¸‚",
#     "å°å—ç¸£": "å°å—å¸‚", "è‡ºå—ç¸£": "å°å—å¸‚",
#     "é«˜é›„ç¸£": "é«˜é›„å¸‚",
#     "è‡º": "å°",
#     "ã€€": "", "â€“": "-",
#     "ï¼ˆ": "(", "ï¼‰": ")"
# }

# FULLWIDTH_DIGIT_MAP = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789')
# ADDRESS_UNIT_PATTERN = re.compile(r'(ç¸£|å¸‚|å€|é„‰|é®|æ‘|é‡Œ|è·¯|è¡—|æ®µ|å··|å¼„|è™Ÿ|æ¨“|è™Ÿä¹‹\d+|è™Ÿ-\d+|æ¨“ä¹‹\d+)')

# # åˆå§‹åŒ– geopy + rate limiterï¼ˆé¿å…æŸ¥è©¢å¤ªå¿«è¢« banï¼‰
# geolocator = Nominatim(user_agent="geo_powerbi")
# geocode = RateLimiter(geolocator.geocode, min_delay_seconds=5)


# # =======================
# # ğŸ§° å·¥å…·å‡½æ•¸
# # =======================

# def normalize_tw_address(addr, separate_parts=True):
#     if not isinstance(addr, str) or not addr.strip():
#         return None

#     addr = addr.strip().translate(FULLWIDTH_DIGIT_MAP)

#     # æ›¿æ›å¸¸è¦‹åœ°åèˆ‡ç¬¦è™Ÿ
#     for old, new in ADDRESS_REPLACE_MAP.items():
#         addr = addr.replace(old, new)

#     addr = re.sub(r'^\d{3,5}', '', addr).strip()  # ç§»é™¤éƒµéå€è™Ÿ
#     if not addr.startswith("å°ç£"):
#         addr = "å°ç£ " + addr
#     addr = re.sub(r'[ï¼Œã€‚ï¼ã€\s]+$', '', addr)     # ç§»é™¤çµå°¾æ¨™é»
#     addr = re.sub(r'\s+', '', addr)              # ç§»é™¤å¤šé¤˜ç©ºç™½

#     if separate_parts:
#         addr = ADDRESS_UNIT_PATTERN.sub(r'\1 ', addr)
#         addr = re.sub(r'\s+', ' ', addr).strip()

#     return addr


# def try_fix_minguo_with_letter(val):
#     if pd.isna(val):
#         return val

#     s = str(val).lower()
#     char_map = {'a': '1', 'b': '2', 'c': '3', 'd': '4', 'e': '5',
#                 'f': '6', 'g': '7', 'h': '8', 'i': '9', 'o': '0', 'l': '1'}
#     s_fixed = ''.join(char_map.get(c, c) for c in s)

#     if re.fullmatch(r'\d{7}', s_fixed):
#         try:
#             year = int(s_fixed[:3]) + 1911
#             month = int(s_fixed[3:5])
#             day = int(s_fixed[5:7])
#             return f"{year:04d}-{month:02d}-{day:02d}"
#         except:
#             return None
#     return None


# # =======================
# # ğŸ“¦ æª”æ¡ˆè™•ç†ä¸»åŠŸèƒ½
# # =======================

# def convert_single_csv_to_parquet(csv_path, skiprows=1, output_path=None):
#     try:
#         df = pd.read_csv(csv_path, skiprows=skiprows)
#     except Exception as e:
#         print(f"[éŒ¯èª¤] è®€å– CSV å¤±æ•—ï¼š{csv_path}\nåŸå› ï¼š{e}")
#         return None

#     if output_path is None:
#         base, _ = os.path.splitext(csv_path)
#         output_path = base + '.parquet'

#     try:
#         df.to_parquet(output_path, engine="pyarrow", index=False)
#         print(f"âœ… è½‰æ›å®Œæˆ âœ {output_path}")
#         return output_path
#     except Exception as e:
#         print(f"[éŒ¯èª¤] ç„¡æ³•å¯«å…¥ Parquetï¼š{output_path}\nåŸå› ï¼š{e}")
#         return None


# def fix_date_columns_custom(parquet_path, fill_strategy='mode', save=False, overwrite=False):
#     try:
#         df = pd.read_parquet(parquet_path)
#     except Exception as e:
#         print(f"âŒ è®€å– parquet æª”æ¡ˆå¤±æ•—: {parquet_path}\n{e}")
#         return None

#     date_cols = [col for col in df.columns if any(k in col.lower() for k in ['date', 'day', 'year'])]
#     if not date_cols:
#         print("âŒ æ²’æ‰¾åˆ°ä»»ä½•æ—¥æœŸç›¸é—œæ¬„ä½ã€‚")
#         return df

#     print(f"ğŸ—‚ï¸ æ‰¾åˆ°æ—¥æœŸæ¬„ä½: {date_cols}")

#     for col in date_cols:
#         try:
#             print(f"\nğŸ”§ è™•ç†æ¬„ä½: {col}")
#             original = df[col].astype(str).str.strip().str.replace(r'\.0$', '', regex=True)

#             fix_mask = original.str.contains(r'[a-zA-Z]', na=False)
#             original.loc[fix_mask] = original[fix_mask].apply(try_fix_minguo_with_letter)

#             mask = original.str.match(r'^\d{10,}$').fillna(False)
#             original = original.where(~mask)

#             # æ°‘åœ‹è½‰æ›èˆ‡æ ¼å¼æ¸…æ´—
#             original = original.str.replace(r'^(\d{3})(\d{2})(\d{2})$',
#                 lambda m: f"{int(m.group(1)) + 1911}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", regex=True)

#             original = original.str.replace(r'^(\d{2})(\d{2})(\d{2})$',
#                 lambda m: f"{int(m.group(1)) + 1911}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", regex=True)

#             original = original.str.replace(r'^(\d{2,3})[./-](\d{1,2})[./-](\d{1,2})$',
#                 lambda m: f"{int(m.group(1)) + 1911}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", regex=True)

#             original = original.str.replace(r'^(\d{4})[./-](\d{1,2})$', r'\1-\2-01', regex=True)

#             original = original.str.replace(r'^(\d{2})(\d{2})$',
#                 lambda m: f"{int(m.group(1)) + 1911}-{int(m.group(2)):02d}-01", regex=True)

#             original = original.str.replace(r'^(\d{2})[./-](\d{1,2})[./-](\d{1,2})$',
#                 lambda m: (f"20{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"
#                            if int(m.group(1)) < 30 else
#                            f"19{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}"), regex=True)

#             df[col] = pd.to_datetime(original, format='%Y-%m-%d', errors='coerce')

#         except Exception as e:
#             print(f"âŒ è™•ç†æ¬„ä½ {col} ç™¼ç”ŸéŒ¯èª¤ï¼š\n{e}")

#     if save:
#         try:
#             output_path = parquet_path if overwrite else parquet_path.replace('.parquet', '_fixed.parquet')
#             df.to_parquet(output_path, index=False)
#             print(f"ğŸ’¾ å·²å„²å­˜ä¿®æ­£æª”è‡³ï¼š{output_path}")
#         except Exception as e:
#             print(f"âŒ å„²å­˜æª”æ¡ˆå¤±æ•—ï¼š\n{e}")

#     return df


# def add_lat_lon_from_address(df, address_column='address'):
#     if address_column not in df.columns:
#         print(f"âš ï¸ æ¬„ä½ {address_column} ä¸å­˜åœ¨ï¼Œè·³éç¶“ç·¯åº¦è™•ç†ã€‚")
#         return df

#     print(f"ğŸŒ é–‹å§‹ç¶“ç·¯åº¦æŸ¥è©¢ï¼ˆæ¬„ä½ï¼š{address_column}ï¼‰")

#     def safe_geocode(addr):
#         if pd.isna(addr) or not str(addr).strip():
#             return None
#         norm_addr = normalize_tw_address(addr)
#         try:
#             location = geocode(norm_addr)
#             if not location:
#                 print(f"â— æŸ¥ç„¡åº§æ¨™ï¼š{norm_addr}")
#             return location
#         except Exception as e:
#             print(f"âŒ æŸ¥è©¢å¤±æ•—ï¼š{norm_addr}ï¼ŒåŸå› ï¼š{e}")
#             return None

#     locations = df[address_column].apply(safe_geocode)
#     df['latitude'] = locations.apply(lambda loc: loc.latitude if loc else None)
#     df['longitude'] = locations.apply(lambda loc: loc.longitude if loc else None)

#     found = df['latitude'].notna().sum()
#     print(f"âœ… ç¶“ç·¯åº¦å–å¾—ç‡ï¼š{found}/{len(df)}ï¼ˆ{found / len(df):.1%}ï¼‰")

#     return df


# # =======================
# # ğŸš€ ä¸»ç¨‹å¼å…¥å£
# # =======================

# if __name__ == '__main__':
#     base_path = os.path.dirname(__file__)
#     csv_folder = os.path.join(base_path, 'data_csv')

#     for filename in os.listdir(csv_folder):
#         if filename.endswith('.csv'):
#             full_csv_path = os.path.join(csv_folder, filename)
#             print(f"\nğŸ“ è™•ç†æª”æ¡ˆï¼š{full_csv_path}")

#             parquet_path = convert_single_csv_to_parquet(full_csv_path, skiprows=1)

#             if parquet_path:
#                 df = fix_date_columns_custom(parquet_path, fill_strategy='none', save=False, overwrite=False)
#                 df = add_lat_lon_from_address(df, address_column='address')

#                 final_output = parquet_path.replace('.parquet', '_final.parquet')
#                 df.to_parquet(final_output, index=False)
#                 print(f"âœ… æœ€çµ‚æª”æ¡ˆå„²å­˜è‡³ï¼š{final_output}")
#             else:
#                 print(f"âš ï¸ ç„¡æ³•è™•ç†æª”æ¡ˆï¼š{full_csv_path}")

